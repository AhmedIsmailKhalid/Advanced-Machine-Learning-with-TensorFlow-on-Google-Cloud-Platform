{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1> Structured data prediction using Cloud ML Engine </h1>\n",
    "\n",
    "This notebook illustrates:\n",
    "<ol>\n",
    "<li> Creating datasets for Machine Learning using Dataflow\n",
    "<li> Creating a model using the high-level Estimator API \n",
    "<li> Training on Cloud ML Engine\n",
    "<li> Deploying model\n",
    "<li> Predicting with model\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting apache-beam[gcp]==2.16.0\n",
      "  Using cached https://files.pythonhosted.org/packages/0f/15/a8065042472311383f34d94fe3ff611cc7ab092b0bf502ad097acb7406e3/apache_beam-2.16.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting avro-python3<2.0.0,>=1.8.1; python_version >= \"3.0\" (from apache-beam[gcp]==2.16.0)\n",
      "Collecting mock<3.0.0,>=1.0.1 (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl\n",
      "Collecting future<1.0.0,>=0.16.0 (from apache-beam[gcp]==2.16.0)\n",
      "Collecting oauth2client<4,>=2.0.1 (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/7b/bc893e35d6ca46a72faa4b9eaac25c687ce60e1fbe978993fe2de1b0ff0d/oauth2client-3.0.0.tar.gz\n",
      "Collecting pymongo<4.0.0,>=3.8.0 (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/5b/08/c0e0f1dff3a996f5ef4ba0cedf5d4c900748bbe5f1a811e78880678046d2/pymongo-3.10.1-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting pytz>=2018.3 (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl\n",
      "Collecting protobuf<4,>=3.5.0.post1 (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/ef/56/10999d97e62eba72a12ebd147d806fa702ab82a620e28f6bc3e5d2c59e34/protobuf-3.11.3-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting fastavro<0.22,>=0.21.4 (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/ac/7d/e63a1ba78326e42a69bda88b1fcfca22ddd773c4cc51ae85b3b869abcff2/fastavro-0.21.24-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting pyyaml<4.0.0,>=3.12 (from apache-beam[gcp]==2.16.0)\n",
      "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/82/39/2c0879b1bcfd1f6ad078eb210d09dbce21072386a3997074ee91e60ddc5a/hdfs-2.5.8.tar.gz\n",
      "Collecting pyarrow<0.15.0,>=0.11.1; python_version >= \"3.0\" or platform_system != \"Windows\" (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/02/3a/6b9474507e6abbd2bbe715627fec991e3c71f5ea71daff1ebddeddab0208/pyarrow-0.14.1-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting httplib2<=0.12.0,>=0.8 (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/ce/ed/803905d670b52fa0edfdd135337e545b4496c2ab3a222f1449b7256eb99f/httplib2-0.12.0.tar.gz\n",
      "Collecting python-dateutil<3,>=2.8.0 (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting pydot<2,>=1.2.0 (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/33/d1/b1479a770f66d962f545c2101630ce1d5592d90cb4f083d38862e93d16d2/pydot-1.4.1-py2.py3-none-any.whl\n",
      "Collecting crcmod<2.0,>=1.7 (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/6b/b0/e595ce2a2527e169c3bcd6c33d2473c1918e0b7f6826a043ca1245dd4e5b/crcmod-1.7.tar.gz\n",
      "Collecting grpcio<2,>=1.12.1 (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/cf/7a/9744998129fce7e29c5f2d8b0f545913b7383e65d8366fc0ae98d11936af/grpcio-1.28.1.tar.gz\n",
      "Collecting dill<0.3.1,>=0.3.0 (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/39/7a/70803635c850e351257029089d38748516a280864c97cbc73087afef6d51/dill-0.3.0.tar.gz\n",
      "Collecting google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\" (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/d0/aa/29cbcf8cf7d08ce2d55b9dce858f7c632b434cb6451bed17cb4275804217/google_cloud_datastore-1.7.4-py2.py3-none-any.whl\n",
      "Collecting google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\" (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/95/af/0ef7d097a1d5ad0c843867600e86de915e8ab8864740f49a4636cfb51af6/google_cloud_bigtable-1.0.0-py2.py3-none-any.whl\n",
      "Collecting google-cloud-core<2,>=0.28.1; extra == \"gcp\" (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/89/3c/8a7531839028c9690e6d14c650521f3bbaf26e53baaeb2784b8c3eb2fb97/google_cloud_core-1.3.0-py2.py3-none-any.whl\n",
      "Collecting google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\" (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/a4/96/1b9cf1d43869c47a205aad411dac7c3040df6093d63c39273fa4d4c45da7/google_cloud_bigquery-1.17.1-py2.py3-none-any.whl\n",
      "Collecting cachetools<4,>=3.1.0; extra == \"gcp\" (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Collecting google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\" (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/d3/91/07a82945a7396ea34debafd476724bb5fc267c292790fdf2138c693f95c5/google_cloud_pubsub-1.0.2-py2.py3-none-any.whl\n",
      "Collecting google-apitools<0.5.29,>=0.5.28; extra == \"gcp\" (from apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/7f/32/df3e36fd705a00092f1ffa9f41ce1df8dcb594ae313d239b87861a41fc2e/google-apitools-0.5.28.tar.gz\n",
      "Collecting six>=1.9 (from mock<3.0.0,>=1.0.1->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
      "Collecting pbr>=0.11 (from mock<3.0.0,>=1.0.1->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/7a/db/a968fd7beb9fe06901c1841cb25c9ccb666ca1b9a19b114d1bbedf1126fc/pbr-5.4.4-py2.py3-none-any.whl\n",
      "Collecting pyasn1>=0.1.7 (from oauth2client<4,>=2.0.1->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.0.5 (from oauth2client<4,>=2.0.1->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl\n",
      "Collecting rsa>=3.1.4 (from oauth2client<4,>=2.0.1->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting setuptools (from protobuf<4,>=3.5.0.post1->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/a0/df/635cdb901ee4a8a42ec68e480c49f85f4c59e8816effbf57d9e6ee8b3588/setuptools-46.1.3-py3-none-any.whl\n",
      "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/a2/55/8f8cab2afd404cf578136ef2cc5dfb50baa1761b68c9da1fb1e4eed343c9/docopt-0.6.2.tar.gz\n",
      "Collecting requests>=2.7.0 (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl\n",
      "Collecting numpy>=1.14 (from pyarrow<0.15.0,>=0.11.1; python_version >= \"3.0\" or platform_system != \"Windows\"->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/ff/18/c0b937e2f84095ae230196899e56d1d7d76c8e8424fb235ed7e5bb6d68af/numpy-1.18.2-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting pyparsing>=2.1.4 (from pydot<2,>=1.2.0->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/5d/bc/1e58593167fade7b544bfe9502a26dc860940a79ab306e651e7f13be68c2/pyparsing-2.4.6-py2.py3-none-any.whl\n",
      "Collecting google-api-core[grpc]<2.0.0dev,>=1.6.0 (from google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\"->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/63/7e/a523169b0cc9ce62d56e07571db927286a94b1a5f51ac220bd97db825c77/google_api_core-1.16.0-py2.py3-none-any.whl\n",
      "Collecting grpc-google-iam-v1<0.13dev,>=0.12.3 (from google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\"->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/19/2060c8faa325fddc09aa67af98ffcb6813f39a0ad805679fa64815362b3a/grpc-google-iam-v1-0.12.3.tar.gz\n",
      "Collecting google-resumable-media<0.5.0dev,>=0.3.1 (from google-cloud-bigquery<1.18.0,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/96/d7/b29a41b01b854480891dfc408211ffb0cc7a2a3d5f15a3b6740ec18c845b/google_resumable_media-0.4.1-py2.py3-none-any.whl\n",
      "Collecting fasteners>=0.14 (from google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/18/bd/55eb2d6397b9c0e263af9d091ebdb756b15756029b3cededf6461481bc63/fasteners-0.15-py2.py3-none-any.whl\n",
      "Collecting idna<3,>=2.5 (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/89/e3/afebe61c546d18fb1709a61bee788254b40e736cff7271c7de5de2dc4128/idna-2.9-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl\n",
      "Collecting chardet<4,>=3.0.2 (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/e8/74/6e4f91745020f967d09332bb2b8b9b10090957334692eb88ea4afe91b77f/urllib3-1.25.8-py2.py3-none-any.whl\n",
      "Collecting google-auth<2.0dev,>=0.4.0 (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\"->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/dc/1a/c3c2f3aa4190d8154a146ad33aa5479c8d193cc6211abe5c535921d93389/google_auth-1.13.1-py2.py3-none-any.whl\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0 (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\"->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/46/168fd780f594a4d61122f7f3dc0561686084319ad73b4febbf02ae8b32cf/googleapis-common-protos-1.51.0.tar.gz\n",
      "Collecting monotonic>=0.1 (from fasteners>=0.14->google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]==2.16.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: oauth2client, hdfs, httplib2, crcmod, grpcio, dill, google-apitools, docopt, grpc-google-iam-v1, googleapis-common-protos\n",
      "  Running setup.py bdist_wheel for oauth2client ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/48/f7/87/b932f09c6335dbcf45d916937105a372ab14f353a9ca431d7d\n",
      "  Running setup.py bdist_wheel for hdfs ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/fe/a7/05/23e3699975fc20f8a30e00ac1e515ab8c61168e982abe4ce70\n",
      "  Running setup.py bdist_wheel for httplib2 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/6d/41/4b/2b369d6e2b7eaebcdd423516d3fb659c7658c16a2be8fd04ec\n",
      "  Running setup.py bdist_wheel for crcmod ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/50/24/4d/4580ca4a299f1ad6fd63443e6e584cb21e9a07988e4aa8daac\n",
      "  Running setup.py bdist_wheel for grpcio ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/00/4d/5f/07d0d4283911d2b917b867a11b1622d9d2cc8c286eefd10c33\n",
      "  Running setup.py bdist_wheel for dill ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/c9/de/a4/a91eec4eea652104d8c81b633f32ead5eb57d1b294eab24167\n",
      "  Running setup.py bdist_wheel for google-apitools ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/d6/c2/92/837e8a4d649a209dff85b38d7fbb576b4b480738be70865f29\n",
      "  Running setup.py bdist_wheel for docopt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/9b/04/dd/7daf4150b6d9b12949298737de9431a324d4b797ffd63f526e\n",
      "  Running setup.py bdist_wheel for grpc-google-iam-v1 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/de/3a/83/77a1e18e1a8757186df834b86ce6800120ac9c79cd8ca4091b\n",
      "  Running setup.py bdist_wheel for googleapis-common-protos ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyter/.cache/pip/wheels/2c/f9/7f/6eb87e636072bf467e25348bbeb96849333e6a080dca78f706\n",
      "Successfully built oauth2client hdfs httplib2 crcmod grpcio dill google-apitools docopt grpc-google-iam-v1 googleapis-common-protos\n",
      "Installing collected packages: avro-python3, six, pbr, mock, future, httplib2, pyasn1, pyasn1-modules, rsa, oauth2client, pymongo, pytz, setuptools, protobuf, fastavro, pyyaml, docopt, idna, certifi, chardet, urllib3, requests, hdfs, numpy, pyarrow, python-dateutil, pyparsing, pydot, crcmod, grpcio, dill, cachetools, google-auth, googleapis-common-protos, google-api-core, google-cloud-core, google-cloud-datastore, grpc-google-iam-v1, google-cloud-bigtable, google-resumable-media, google-cloud-bigquery, google-cloud-pubsub, monotonic, fasteners, google-apitools, apache-beam\n",
      "Successfully installed apache-beam-2.16.0 avro-python3-1.9.2.1 cachetools-3.1.1 certifi-2019.11.28 chardet-3.0.4 crcmod-1.7 dill-0.3.0 docopt-0.6.2 fastavro-0.21.24 fasteners-0.15 future-0.18.2 google-api-core-1.16.0 google-apitools-0.5.28 google-auth-1.13.1 google-cloud-bigquery-1.17.1 google-cloud-bigtable-1.0.0 google-cloud-core-1.3.0 google-cloud-datastore-1.7.4 google-cloud-pubsub-1.0.2 google-resumable-media-0.4.1 googleapis-common-protos-1.51.0 grpc-google-iam-v1-0.12.3 grpcio-1.28.1 hdfs-2.5.8 httplib2-0.12.0 idna-2.9 mock-2.0.0 monotonic-1.5 numpy-1.18.2 oauth2client-3.0.0 pbr-5.4.4 protobuf-3.11.3 pyarrow-0.14.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pydot-1.4.1 pymongo-3.10.1 pyparsing-2.4.6 python-dateutil-2.8.1 pytz-2019.3 pyyaml-3.13 requests-2.23.0 rsa-4.0 setuptools-46.1.3 six-1.14.0 urllib3-1.25.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user apache-beam[gcp]==2.16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Run the command again if you are getting oauth2client error.\n",
    "<b>Restart</b> the kernel before proceeding further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "BUCKET = 'qwiklabs-gcp-00-730a32804c55' # Replace with the your bucket name\n",
    "PROJECT = 'qwiklabs-gcp-00-730a32804c55' # Replace with your project-id\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/checkpoint...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/events.out.tfevents.1529347394.cmle-training-master-ab97329ccf-0-xfhjt...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/eval/events.out.tfevents.1529347627.cmle-training-master-ab97329ccf-0-xfhjt...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/export/exporter/1529347629/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/export/exporter/1529347629/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/export/exporter/1529348269/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/export/exporter/1529347926/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/export/exporter/1529347629/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-141975.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/export/exporter/1529348269/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-141975.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-141975.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/export/exporter/1529347926/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/export/exporter/1529347926/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/export/exporter/1529348269/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-141975.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/graph.pbtxt...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-295591.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-295591.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-141975.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-295591.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-295591.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-317465.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-317465.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-295591.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-317465.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-317465.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/1/model.ckpt-317465.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/checkpoint...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/eval/events.out.tfevents.1529349910.cmle-training-master-3034bab816-0-sjbrw...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/events.out.tfevents.1529349469.cmle-training-master-3034bab816-0-sjbrw...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/export/exporter/1529349912/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/export/exporter/1529349912/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/export/exporter/1529349912/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/export/exporter/1529350256/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/export/exporter/1529350256/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/export/exporter/1529350256/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/graph.pbtxt...       \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-25.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-25.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-25.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-25.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-25.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-36177.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-36177.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-36177.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-36177.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-41931.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-36177.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-41931.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-41931.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-41931.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/10/model.ckpt-41931.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/checkpoint...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/events.out.tfevents.1529350033.cmle-training-master-147ed9d6ac-0-xxzz7...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/eval/events.out.tfevents.1529350196.cmle-training-master-147ed9d6ac-0-xxzz7...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/export/exporter/1529350198/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/export/exporter/1529350198/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/export/exporter/1529350198/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/export/exporter/1529350524/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/export/exporter/1529350524/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/export/exporter/1529350524/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/graph.pbtxt...       \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-1.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-1.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-1.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-1.meta... \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-1.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-35698.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-35698.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-35698.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-35698.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-35698.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-39142.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-39142.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-39142.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-39142.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/11/model.ckpt-39142.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/checkpoint...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/eval/events.out.tfevents.1529350215.cmle-training-master-91e18bf984-0-glpz6...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/events.out.tfevents.1529350059.cmle-training-master-91e18bf984-0-glpz6...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/export/exporter/1529350216/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/export/exporter/1529350216/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/export/exporter/1529350216/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/export/exporter/1529350499/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/export/exporter/1529350499/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/export/exporter/1529350499/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/graph.pbtxt...       \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/model.ckpt-1.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/model.ckpt-1.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/model.ckpt-1.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/model.ckpt-1.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/model.ckpt-1.meta... \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/model.ckpt-52777.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/model.ckpt-52777.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/model.ckpt-52777.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/model.ckpt-52777.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/12/model.ckpt-52777.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/checkpoint...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/eval/events.out.tfevents.1529350568.cmle-training-master-2951e6ce4f-0-cjrmj...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/events.out.tfevents.1529350538.cmle-training-master-2951e6ce4f-0-cjrmj...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/export/exporter/1529350570/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/export/exporter/1529350570/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/export/exporter/1529350570/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/export/exporter/1529350871/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/export/exporter/1529350871/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/export/exporter/1529350871/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/export/exporter/1529350905/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/export/exporter/1529350905/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/export/exporter/1529350905/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/graph.pbtxt...       \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-1.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-1.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-1.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-1.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-1.meta... \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-42291.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-42291.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-42291.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-42291.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-42291.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-43297.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-43297.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-43297.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-43297.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/13/model.ckpt-43297.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/checkpoint...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/eval/events.out.tfevents.1529350566.cmle-training-master-58d1f4795d-0-8mrg6...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/events.out.tfevents.1529350542.cmle-training-master-58d1f4795d-0-8mrg6...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/export/exporter/1529350568/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/export/exporter/1529350568/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/export/exporter/1529350568/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/graph.pbtxt...       \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/model.ckpt-1.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/model.ckpt-1.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/model.ckpt-1.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/model.ckpt-1.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/model.ckpt-1.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/model.ckpt-39142.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/model.ckpt-39142.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/model.ckpt-39142.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/model.ckpt-39142.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/model.ckpt-39142_temp_34004248bb4b436d9a67b7e638b0bbb3/part-00000-of-00003.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/checkpoint...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/model.ckpt-39142_temp_34004248bb4b436d9a67b7e638b0bbb3/part-00001-of-00003.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/eval/events.out.tfevents.1529350856.cmle-training-master-c4e81fbb25-0-sz655...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/14/model.ckpt-39142_temp_34004248bb4b436d9a67b7e638b0bbb3/part-00002-of-00003.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/events.out.tfevents.1529350831.cmle-training-master-c4e81fbb25-0-sz655...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/export/exporter/1529350858/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/export/exporter/1529350858/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/export/exporter/1529350858/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/export/exporter/1529351128/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/export/exporter/1529351128/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/export/exporter/1529351128/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/graph.pbtxt...       \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/model.ckpt-1.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/model.ckpt-1.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/model.ckpt-1.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/model.ckpt-1.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/model.ckpt-1.meta... \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/model.ckpt-39142.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/model.ckpt-39142.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/model.ckpt-39142.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/model.ckpt-39142.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/15/model.ckpt-39142.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/checkpoint...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/eval/events.out.tfevents.1529351171.cmle-training-master-3523a35558-0-92n89...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/events.out.tfevents.1529350997.cmle-training-master-3523a35558-0-92n89...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/export/exporter/1529351172/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/export/exporter/1529351172/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/export/exporter/1529351172/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/export/exporter/1529351482/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/export/exporter/1529351482/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/export/exporter/1529351482/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/graph.pbtxt...       \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-1.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-1.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-1.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-1.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-1.meta... \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-37295.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-37295.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-37295.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-37295.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-37295.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-39146.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-39146.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-39146.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-39146.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/16/model.ckpt-39146.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/eval/events.out.tfevents.1529351354.cmle-training-master-dc3a8c26ae-0-v6sld...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/checkpoint...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/events.out.tfevents.1529351326.cmle-training-master-dc3a8c26ae-0-v6sld...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/export/exporter/1529351355/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/export/exporter/1529351355/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/export/exporter/1529351355/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/export/exporter/1529351625/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/export/exporter/1529351625/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/export/exporter/1529351625/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/graph.pbtxt...       \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/model.ckpt-1.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/model.ckpt-1.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/model.ckpt-1.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/model.ckpt-1.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/model.ckpt-1.meta... \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/model.ckpt-39300.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/model.ckpt-39300.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/model.ckpt-39300.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/model.ckpt-39300.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/17/model.ckpt-39300.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/checkpoint...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/eval/events.out.tfevents.1529351495.cmle-training-master-d1e5f6ad31-0-dbw9g...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/events.out.tfevents.1529351469.cmle-training-master-d1e5f6ad31-0-dbw9g...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/export/exporter/1529351496/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/export/exporter/1529351496/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/export/exporter/1529351496/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/export/exporter/1529351787/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/export/exporter/1529351787/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/export/exporter/1529351787/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/graph.pbtxt...       \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/model.ckpt-1.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/model.ckpt-1.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/model.ckpt-1.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/model.ckpt-1.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/model.ckpt-1.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/model.ckpt-39218.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/model.ckpt-39218.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/model.ckpt-39218.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/model.ckpt-39218.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/18/model.ckpt-39218.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/checkpoint...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/eval/events.out.tfevents.1529351745.cmle-training-master-67c24f2848-0-sqcqw...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/events.out.tfevents.1529351716.cmle-training-master-67c24f2848-0-sqcqw...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/export/exporter/1529351747/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/export/exporter/1529351747/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/export/exporter/1529351747/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/export/exporter/1529352047/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/export/exporter/1529352047/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/export/exporter/1529352047/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/export/exporter/1529352079/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/export/exporter/1529352079/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/export/exporter/1529352079/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/graph.pbtxt...       \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-1.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-1.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-1.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-1.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-1.meta... \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-39733.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-39733.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-39733.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-39733.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-40167.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-39733.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-40167.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-40167.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-40167.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/19/model.ckpt-40167.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/checkpoint...         \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/eval/events.out.tfevents.1529347521.cmle-training-master-562372026f-0-vkqw8...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/events.out.tfevents.1529347361.cmle-training-master-562372026f-0-vkqw8...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/export/exporter/1529347523/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/export/exporter/1529347523/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/export/exporter/1529347523/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/export/exporter/1529347809/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/export/exporter/1529347809/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/export/exporter/1529347809/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/graph.pbtxt...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/model.ckpt-22.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/model.ckpt-22.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/model.ckpt-22.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/model.ckpt-22.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/model.ckpt-22.meta... \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/model.ckpt-41414.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/model.ckpt-41414.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/model.ckpt-41414.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/model.ckpt-41414.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/2/model.ckpt-41414.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/checkpoint...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/eval/events.out.tfevents.1529352130.cmle-training-master-9194a02df3-0-2jhm6...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/events.out.tfevents.1529351968.cmle-training-master-9194a02df3-0-2jhm6...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/export/exporter/1529352132/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/export/exporter/1529352132/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/export/exporter/1529352132/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/export/exporter/1529352442/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/export/exporter/1529352442/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/export/exporter/1529352442/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/graph.pbtxt...       \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-14.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-14.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-14.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-14.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-14.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-37770.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-37770.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-37770.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-37770.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-37770.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-39222.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-39222.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-39222.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-39222.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/20/model.ckpt-39222.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/checkpoint...         \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/eval/events.out.tfevents.1529347749.cmle-training-master-32c4950845-0-l8mtk...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/events.out.tfevents.1529347399.cmle-training-master-32c4950845-0-l8mtk...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529347751/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529347751/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529347751/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529348048/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529348048/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529348048/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529348350/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529348350/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529348350/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529348648/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529348648/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529348648/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529348952/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529348952/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529348952/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529349251/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529349251/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/export/exporter/1529349251/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/graph.pbtxt...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-1013057.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-1013057.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-1013057.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-1013057.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-1013057.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-1269118.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-1269118.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-1269118.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-1269118.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-1269118.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-754997.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-754997.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-754997.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-754997.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/3/model.ckpt-754997.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/4/events.out.tfevents.1529347396.cmle-training-master-f54adf8366-0-9vbn8...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/checkpoint...         \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/eval/events.out.tfevents.1529347752.cmle-training-master-a7c3435684-0-k49qb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/events.out.tfevents.1529347396.cmle-training-master-a7c3435684-0-k49qb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529347753/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529347753/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529347753/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529348051/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529348051/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529348051/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529348350/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529348350/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529348350/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529348651/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529348651/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529348651/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529348952/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529348952/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/export/exporter/1529348952/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/graph.pbtxt...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-572586.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-572586.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-572586.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-572586.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-572586.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-767695.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-767695.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-767695.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-767695.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-767695.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-959128.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-959128.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-959128.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-959128.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/5/model.ckpt-959128.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/checkpoint...         \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/eval/events.out.tfevents.1529348214.cmle-training-master-ec16a0895d-0-xtx5j...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/events.out.tfevents.1529348187.cmle-training-master-ec16a0895d-0-xtx5j...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/export/exporter/1529348216/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/export/exporter/1529348216/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/export/exporter/1529348216/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/export/exporter/1529348496/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/export/exporter/1529348496/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/export/exporter/1529348496/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/graph.pbtxt...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/model.ckpt-1.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/model.ckpt-1.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/model.ckpt-1.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/model.ckpt-1.index... \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/model.ckpt-1.meta...  \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/model.ckpt-41935.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/model.ckpt-41935.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/model.ckpt-41935.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/model.ckpt-41935.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/6/model.ckpt-41935.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/checkpoint...         \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/eval/events.out.tfevents.1529348617.cmle-training-master-34de34160b-0-kzg6l...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/export/exporter/1529348619/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/events.out.tfevents.1529348592.cmle-training-master-34de34160b-0-kzg6l...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/export/exporter/1529348619/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/export/exporter/1529348619/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/export/exporter/1529348918/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/export/exporter/1529348918/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/export/exporter/1529348918/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/export/exporter/1529349139/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/export/exporter/1529349139/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/export/exporter/1529349139/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/graph.pbtxt...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-1.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-1.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-1.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-1.index... \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-1.meta...  \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-179951.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-179951.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-179951.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-179951.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-179951.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-317466.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-317466.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-317466.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-317466.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/7/model.ckpt-317466.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/checkpoint...         \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/eval/events.out.tfevents.1529348857.cmle-training-master-4cc903f03c-0-wgg9f...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/events.out.tfevents.1529348822.cmle-training-master-4cc903f03c-0-wgg9f...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/export/exporter/1529348859/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/export/exporter/1529348859/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/export/exporter/1529348859/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/export/exporter/1529349124/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/export/exporter/1529349124/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/export/exporter/1529349124/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/graph.pbtxt...        \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/model.ckpt-1.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/model.ckpt-1.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/model.ckpt-1.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/model.ckpt-1.index... \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/model.ckpt-1.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/model.ckpt-40166.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/model.ckpt-40166.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/model.ckpt-40166.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/model.ckpt-40166.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/checkpoint...         \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/8/model.ckpt-40166.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/eval/events.out.tfevents.1529349999.cmle-training-master-48340617c9-0-n4cg7...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/events.out.tfevents.1529349470.cmle-training-master-48340617c9-0-n4cg7...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/export/exporter/1529350000/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/export/exporter/1529350000/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/export/exporter/1529350000/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/export/exporter/1529350336/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/export/exporter/1529350336/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/export/exporter/1529350336/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/graph.pbtxt...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-1.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-1.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-1.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-1.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-1.meta...  \n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-35917.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-35917.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-35917.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-35917.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-35917.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-40655.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-40655.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-40655.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-40655.index...\n",
      "Copying gs://cloud-training-demos/babyweight/hyperparam/9/model.ckpt-40655.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/eval.csv-00000-of-00012 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/eval.csv-00001-of-00012 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/eval.csv-00002-of-00012 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/eval.csv-00003-of-00012 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/eval.csv-00004-of-00012 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/eval.csv-00005-of-00012 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/eval.csv-00006-of-00012 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/eval.csv-00007-of-00012 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/eval.csv-00008-of-00012 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/eval.csv-00009-of-00012 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/eval.csv-00010-of-00012 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/eval.csv-00011-of-00012 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00000-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00001-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00002-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00003-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00004-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00005-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00006-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00007-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00008-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00009-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00010-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00011-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00012-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00013-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00014-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00016-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00015-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00017-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00018-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00019-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00020-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00021-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00022-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00023-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00024-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00025-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00026-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00027-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00028-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00029-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00030-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00031-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00032-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00034-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00035-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00033-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00036-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00037-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00038-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00039-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00040-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00041-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/preproc/train.csv-00042-of-00043 [Content-Type=text/plain]...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/checkpoint...        \n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/eval/events.out.tfevents.1529348264.cmle-training-master-a137ac0fff-0-9q8r4...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/events.out.tfevents.1529347276.cmle-training-master-a137ac0fff-0-9q8r4...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/export/exporter/1529355466/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/export/exporter/1529355466/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/export/exporter/1529355466/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/graph.pbtxt...       \n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-342784.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-342784.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-342784.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-342784.index...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-342784.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-376661.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-376661.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-376661.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-376661.index...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-376661.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-390628.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-390628.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-390628.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-390628.index...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model/model.ckpt-390628.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/checkpoint...  \n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/eval/events.out.tfevents.1529348486.cmle-training-master-d20efff6e7-0-gtx4t...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/events.out.tfevents.1529347278.cmle-training-master-d20efff6e7-0-gtx4t...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/export/exporter/1529348487/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/export/exporter/1529348487/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/export/exporter/1529348487/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/export/exporter/1529349318/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/export/exporter/1529349318/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/export/exporter/1529349318/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/export/exporter/1529350150/saved_model.pb...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/export/exporter/1529350150/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/export/exporter/1529350150/variables/variables.index...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/graph.pbtxt...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-1.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-1.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-1.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-483973.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-1.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-1.index...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-483973.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-483973.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-483973.index...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-483973.meta...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-571432.data-00000-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-571432.data-00001-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-571432.data-00002-of-00003...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-571432.index...\n",
      "Copying gs://cloud-training-demos/babyweight/trained_model_tuned/model.ckpt-571432.meta...\n",
      "| [573/573 files][  6.1 GiB/  6.1 GiB] 100% Done                                \n",
      "Operation completed over 573 objects/6.1 GiB.                                    \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi\n",
    "gsutil -m cp -R gs://cloud-training-demos/babyweight gs://${BUCKET}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A variety of factors seem to play a part in the baby's weight.  Male babies are heavier on average than female babies. Teenaged and older moms tend to have lower-weight babies.  Twins, triplets, etc. are lower weight than single births.  Preemies weigh in lower as do babies born to single moms. In addition, it is important to check whether you have enough data (number of babies) for each input value. Otherwise, the model prediction against input values that doesn't have enough data may not be reliable.\n",
    "<p>\n",
    "In the rest of this notebook, we will use machine learning to combine all of these factors to come up with a prediction of a baby's weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2> Create ML dataset using Dataflow </h2>\n",
    "<p>\n",
    "We can use Cloud Dataflow to read in the BigQuery data and write it out as CSV files. \n",
    "\n",
    "Instead of using Beam/Dataflow, I had three other options:\n",
    "<ol>\n",
    "<li> Use Cloud Dataprep to visually author a Dataflow pipeline. Cloud Dataprep also allows me to explore the data, so we could have avoided much of the handcoding of Python/Seaborn calls above as well!\n",
    "<li> Read from BigQuery directly using TensorFlow. \n",
    "<li> Use the BigQuery console (http://bigquery.cloud.google.com) to run a Query and save the result as a CSV file. For larger datasets, you may have to select the option to \"allow large results\" and save the result into a CSV file on Google Cloud Storage.\n",
    "</ol>\n",
    "<p>\n",
    "However, in this case, I want to do some preprocessing, modifying data so that we can simulate what is known if no ultrasound has been performed. If I didn't need preprocessing, I could have used the web console. Also, I prefer to script it out rather than run queries on the user interface, so I am using Cloud Dataflow for the preprocessing.\n",
    "<p>\n",
    "Note that I have set in_test_mode=True in the following code -- this will run the code locally on a small subset of the data -- the full results were copied into your bucket using the following code (in the previous cell):\n",
    "<pre>\n",
    "gsutil -m cp -R gs://cloud-training-demos/babyweight gs://${BUCKET}\n",
    "</pre>\n",
    "If you are running in your own project, change in_test_mode=False; after you launch this, the notebook will appear to be hung. Go to the GCP webconsole to the Dataflow section and monitor the running job. It took about <b>30 minutes</b> for me with autoscaling to 15 workers -- Qwiklabs accounts won't be able scale to that level, and so doing it on Qwiklabs would have taken 3-4 hours. Hence, the short-cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching local job ... hang on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The DirectPipelineResult is being garbage-collected while the DirectRunner is still running the corresponding pipeline. This may lead to incomplete execution of the pipeline if the main thread exits before pipeline completion. Consider using result.wait_until_finish() to wait for completion of pipeline execution.\n",
      "WARNING:root:Dataset qwiklabs-gcp-00-730a32804c55:temp_dataset_a3013f3f6da64a6ebc9a933ff74742be does not exist so we will create it as temporary with location=US\n",
      "WARNING:root:Dataset qwiklabs-gcp-00-730a32804c55:temp_dataset_a7ae98adace143418ec701743c5d39fe does not exist so we will create it as temporary with location=US\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "import datetime\n",
    "\n",
    "def to_csv(rowdict):\n",
    "    # pull columns from BQ and create a line\n",
    "    import hashlib\n",
    "    import copy\n",
    "    CSV_COLUMNS = 'weight_pounds,is_male,mother_age,plurality,gestation_weeks'.split(',')\n",
    "    \n",
    "    # create synthetic data where we assume that no ultrasound has been performed\n",
    "    # and so we don't know sex of the baby. Let's assume that we can tell the difference\n",
    "    # between single and multiple, but that the errors rates in determining exact number\n",
    "    # is difficult in the absence of an ultrasound.\n",
    "    no_ultrasound = copy.deepcopy(rowdict)\n",
    "    w_ultrasound = copy.deepcopy(rowdict)\n",
    "\n",
    "    no_ultrasound['is_male'] = 'Unknown'\n",
    "    if rowdict['plurality'] > 1:\n",
    "      no_ultrasound['plurality'] = 'Multiple(2+)'\n",
    "    else:\n",
    "      no_ultrasound['plurality'] = 'Single(1)'\n",
    "      \n",
    "    # Change the plurality column to strings\n",
    "    w_ultrasound['plurality'] = ['Single(1)', 'Twins(2)', 'Triplets(3)', 'Quadruplets(4)', 'Quintuplets(5)'][rowdict['plurality']-1]\n",
    "    \n",
    "    # Write out two rows for each input row, one with ultrasound and one without\n",
    "    for result in [no_ultrasound, w_ultrasound]:\n",
    "      data = ','.join([str(result[k]) if k in result else 'None' for k in CSV_COLUMNS])\n",
    "      key = hashlib.sha224(data.encode('utf-8')).hexdigest()  # hash the columns to form a key\n",
    "      yield str('{},{}'.format(data, key))\n",
    "  \n",
    "def preprocess(in_test_mode):\n",
    "    job_name = 'preprocess-babyweight-features' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "    \n",
    "    if in_test_mode:\n",
    "        print ('Launching local job ... hang on')\n",
    "        OUTPUT_DIR = './preproc'\n",
    "    else:\n",
    "        print ('Launching Dataflow job {} ... hang on'.format(job_name))\n",
    "        OUTPUT_DIR = 'gs://{0}/babyweight/preproc/'.format(BUCKET)\n",
    "    \n",
    "    options = {\n",
    "        'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "        'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "        'job_name': job_name,\n",
    "        'project': PROJECT,\n",
    "        'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "        'no_save_main_session': True\n",
    "    }\n",
    "    opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "    if in_test_mode:\n",
    "        RUNNER = 'DirectRunner'\n",
    "    else:\n",
    "        RUNNER = 'DataflowRunner'\n",
    "    p = beam.Pipeline(RUNNER, options=opts)\n",
    "    query = \"\"\"\n",
    "SELECT\n",
    "  weight_pounds,\n",
    "  is_male,\n",
    "  mother_age,\n",
    "  plurality,\n",
    "  gestation_weeks,\n",
    "  FARM_FINGERPRINT(CONCAT(CAST(YEAR AS STRING), CAST(month AS STRING))) AS hashmonth\n",
    "FROM\n",
    "  publicdata.samples.natality\n",
    "WHERE year > 2000\n",
    "AND weight_pounds > 0\n",
    "AND mother_age > 0\n",
    "AND plurality > 0\n",
    "AND gestation_weeks > 0\n",
    "AND month > 0\n",
    "    \"\"\"\n",
    "  \n",
    "    if in_test_mode:\n",
    "        query = query + ' LIMIT 100' \n",
    "  \n",
    "    for step in ['train', 'eval']:\n",
    "        if step == 'train':\n",
    "            selquery = 'SELECT * FROM ({}) WHERE ABS(MOD(hashmonth, 4)) < 3'.format(query)\n",
    "        else:\n",
    "            selquery = 'SELECT * FROM ({}) WHERE ABS(MOD(hashmonth, 4)) = 3'.format(query)\n",
    "\n",
    "        (p \n",
    "         | '{}_read'.format(step) >> beam.io.Read(beam.io.BigQuerySource(query=selquery, use_standard_sql=True))\n",
    "         | '{}_csv'.format(step) >> beam.FlatMap(to_csv)\n",
    "         | '{}_out'.format(step) >> beam.io.Write(beam.io.WriteToText(os.path.join(OUTPUT_DIR, '{}.csv'.format(step))))\n",
    "        )\n",
    " \n",
    "    job = p.run()\n",
    "  \n",
    "preprocess(in_test_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'preproc': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"dataflow.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-00-730a32804c55/babyweight/preproc/eval.csv-00000-of-00012\n",
      "gs://qwiklabs-gcp-00-730a32804c55/babyweight/preproc/train.csv-00000-of-00043\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/babyweight/preproc/*-00000*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2> Create TensorFlow model using TensorFlow's Estimator API </h2>\n",
    "<p>\n",
    "First, write an input_fn to read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "CSV_COLUMNS = 'weight_pounds,is_male,mother_age,plurality,gestation_weeks,key'.split(',')\n",
    "LABEL_COLUMN = 'weight_pounds'\n",
    "KEY_COLUMN = 'key'\n",
    "DEFAULTS = [[0.0], ['null'], [0.0], ['null'], [0.0], ['nokey']]\n",
    "TRAIN_STEPS = 1000\n",
    "\n",
    "def read_dataset(prefix, pattern, batch_size=512):\n",
    "    # use prefix to create filename\n",
    "    filename = 'gs://{}/babyweight/preproc/{}*{}*'.format(BUCKET, prefix, pattern)\n",
    "    if prefix == 'train':\n",
    "        mode = tf.estimator.ModeKeys.TRAIN\n",
    "        num_epochs = None # indefinitely\n",
    "    else:\n",
    "        mode = tf.estimator.ModeKeys.EVAL\n",
    "        num_epochs = 1 # end-of-input after this\n",
    "    \n",
    "    # the actual input function passed to TensorFlow\n",
    "    def _input_fn():\n",
    "        # could be a path to one file or a file pattern.\n",
    "        input_file_names = tf.train.match_filenames_once(filename)\n",
    "        filename_queue = tf.train.string_input_producer(\n",
    "            input_file_names, shuffle=True, num_epochs=num_epochs)\n",
    " \n",
    "        # read CSV\n",
    "        reader = tf.TextLineReader()\n",
    "        _, value = reader.read_up_to(filename_queue, num_records=batch_size)\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "          value = tf.train.shuffle_batch([value], batch_size, capacity=10*batch_size, \n",
    "                                         min_after_dequeue=batch_size, enqueue_many=True, \n",
    "                                         allow_smaller_final_batch=False)\n",
    "        value_column = tf.expand_dims(value, -1)\n",
    "        columns = tf.decode_csv(value_column, record_defaults=DEFAULTS)\n",
    "        features = dict(zip(CSV_COLUMNS, columns))\n",
    "        features.pop(KEY_COLUMN)\n",
    "        label = features.pop(LABEL_COLUMN)\n",
    "        return features, label\n",
    "  \n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next, define the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_wide_deep():\n",
    "    # define column types\n",
    "    is_male,mother_age,plurality,gestation_weeks = \\\n",
    "        [\\\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list('is_male', \n",
    "                        ['True', 'False', 'Unknown']),\n",
    "            tf.feature_column.numeric_column('mother_age'),\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list('plurality',\n",
    "                        ['Single(1)', 'Twins(2)', 'Triplets(3)',\n",
    "                         'Quadruplets(4)', 'Quintuplets(5)','Multiple(2+)']),\n",
    "            tf.feature_column.numeric_column('gestation_weeks')\n",
    "        ]\n",
    "\n",
    "    # discretize\n",
    "    age_buckets = tf.feature_column.bucketized_column(mother_age, \n",
    "                        boundaries=np.arange(15,45,1).tolist())\n",
    "    gestation_buckets = tf.feature_column.bucketized_column(gestation_weeks, \n",
    "                        boundaries=np.arange(17,47,1).tolist())\n",
    "      \n",
    "    # sparse columns are wide \n",
    "    wide = [is_male,\n",
    "            plurality,\n",
    "            age_buckets,\n",
    "            gestation_buckets]\n",
    "    \n",
    "    # feature cross all the wide columns and embed into a lower dimension\n",
    "    crossed = tf.feature_column.crossed_column(wide, hash_bucket_size=20000)\n",
    "    embed = tf.feature_column.embedding_column(crossed, 3)\n",
    "    \n",
    "    # continuous columns are deep\n",
    "    deep = [mother_age,\n",
    "            gestation_weeks,\n",
    "            embed]\n",
    "    return wide, deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To predict with the TensorFlow model, we also need a serving input function. We will want all the inputs from our user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        'is_male': tf.placeholder(tf.string, [None]),\n",
    "        'mother_age': tf.placeholder(tf.float32, [None]),\n",
    "        'plurality': tf.placeholder(tf.string, [None]),\n",
    "        'gestation_weeks': tf.placeholder(tf.float32, [None])\n",
    "    }\n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From <ipython-input-14-68490493c118>:22: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-14-68490493c118>:25: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "WARNING:tensorflow:From <ipython-input-14-68490493c118>:30: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:3038: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2655: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:113: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py:2322: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "WARNING:tensorflow:Export includes no default signature!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.learn.python.learn.utils import saved_model_export_utils\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "\n",
    "PATTERN = \"00001-of-\"  # process only one of the shards, for testing purposes\n",
    "\n",
    "def train_and_evaluate(output_dir):\n",
    "    wide, deep = get_wide_deep()\n",
    "    estimator = tf.estimator.DNNLinearCombinedRegressor(\n",
    "                         model_dir=output_dir,\n",
    "                         linear_feature_columns=wide,\n",
    "                         dnn_feature_columns=deep,\n",
    "                         dnn_hidden_units=[64, 32])\n",
    "    train_spec=tf.estimator.TrainSpec(\n",
    "                         input_fn=read_dataset('train', PATTERN),\n",
    "                         max_steps=TRAIN_STEPS)\n",
    "    exporter = tf.estimator.FinalExporter('exporter',serving_input_fn)\n",
    "    eval_spec=tf.estimator.EvalSpec(\n",
    "                         input_fn=read_dataset('eval', PATTERN),\n",
    "                         steps=None,\n",
    "                         exporters=exporter)\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "    \n",
    "shutil.rmtree('babyweight_trained', ignore_errors=True) # start fresh each time\n",
    "train_and_evaluate('babyweight_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\n",
      "eval\n",
      "events.out.tfevents.1586000725.tf-tensorboard-1\n",
      "export\n",
      "graph.pbtxt\n",
      "model.ckpt-0.data-00000-of-00002\n",
      "model.ckpt-0.data-00001-of-00002\n",
      "model.ckpt-0.index\n",
      "model.ckpt-0.meta\n",
      "model.ckpt-1000.data-00000-of-00002\n",
      "model.ckpt-1000.data-00001-of-00002\n",
      "model.ckpt-1000.index\n",
      "model.ckpt-1000.meta\n"
     ]
    }
   ],
   "source": [
    "!ls babyweight_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now that we have the TensorFlow code working on a subset of the data (in the code above, I was reading only the 00001-of-x file), we can package the TensorFlow code up as a Python module and train it on Cloud ML Engine.\n",
    "<p>\n",
    "<h2> Train on Cloud ML Engine </h2>\n",
    "<p>\n",
    "Training on Cloud ML Engine requires:\n",
    "<ol>\n",
    "<li> Making the code a Python package\n",
    "<li> Using gcloud to submit the training code to Cloud ML Engine\n",
    "</ol>\n",
    "<p>\n",
    "The code in model.py is the same as in the above cells. I just moved it to a file so that I could package it up as a module.\n",
    "(explore the <a href=\"babyweight/trainer\">directory structure</a>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def read_dataset(prefix, pattern, batch_size=512):\n",
      "def get_wide_deep():\n",
      "def serving_input_fn():\n",
      "def experiment_fn(output_dir):\n",
      "def train_and_evaluate(output_dir):\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "grep \"^def\" babyweight/trainer/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After moving the code to a package, make sure it works standalone. (Note the --pattern and --train_steps lines so that I am not trying to boil the ocean on my laptop). Even then, this takes about <b>a minute</b> in which you won't see any output ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket=qwiklabs-gcp-00-730a32804c55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/blogs/babyweight/babyweight/trainer/model.py:25: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/blogs/babyweight/babyweight/trainer/model.py:25: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f33d7da1dd0>, '_model_dir': 'babyweight_trained/', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_experimental_max_worker_delay_secs': None, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/training_util.py:236: initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/blogs/babyweight/babyweight/trainer/model.py:48: The name tf.train.match_filenames_once is deprecated. Please use tf.io.match_filenames_once instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/blogs/babyweight/babyweight/trainer/model.py:50: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:199: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/blogs/babyweight/babyweight/trainer/model.py:53: __init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/blogs/babyweight/babyweight/trainer/model.py:58: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n",
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/blogs/babyweight/babyweight/trainer/model.py:60: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:3038: _num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2655: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/adagrad.py:76: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2020-04-04 11:46:11.086635: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_SETTINGS=1\n",
      "   OMP_NUM_THREADS=4\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_HAND_THREAD=false\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_FORKJOIN_FRAMES=true\n",
      "   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_INIT_WAIT=2048\n",
      "   KMP_ITT_PREPARE_DELAY=0\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NEXT_WAIT=1024\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=4M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=4\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USER_LEVEL_MWAIT=false\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=true\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED=false\n",
      "   OMP_NUM_THREADS='4'\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=4M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_TOOL=enabled\n",
      "   OMP_TOOL_LIBRARIES: value is not defined\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "2020-04-04 11:46:11.128585: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2020-04-04 11:46:11.129080: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558e1ab2c380 executing computations on platform Host. Devices:\n",
      "2020-04-04 11:46:11.129128: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-3\n",
      "OMP: Info #156: KMP_AFFINITY: 4 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 1 packages x 2 cores/pkg x 2 threads/core (2 total cores)\n",
      "OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8260 thread 0 bound to OS proc set 0\n",
      "2020-04-04 11:46:11.131263: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2020-04-04 11:46:11.273035: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8284 thread 1 bound to OS proc set 1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8286 thread 2 bound to OS proc set 2\n",
      "INFO:tensorflow:Saving checkpoints for 0 into babyweight_trained/model.ckpt.\n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8282 thread 3 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8289 thread 4 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8290 thread 5 bound to OS proc set 1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8291 thread 6 bound to OS proc set 2\n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8283 thread 7 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8292 thread 8 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8294 thread 10 bound to OS proc set 2\n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8293 thread 9 bound to OS proc set 1\n",
      "INFO:tensorflow:loss = 151339.9, step = 1\n",
      "INFO:tensorflow:global_step/sec: 69.5876\n",
      "INFO:tensorflow:loss = 2620.2783, step = 101 (1.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.434\n",
      "INFO:tensorflow:loss = 844.8474, step = 201 (0.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.769\n",
      "INFO:tensorflow:loss = 778.8917, step = 301 (0.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.407\n",
      "INFO:tensorflow:loss = 671.3259, step = 401 (0.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.154\n",
      "INFO:tensorflow:loss = 614.2434, step = 501 (0.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.451\n",
      "INFO:tensorflow:loss = 659.48474, step = 601 (0.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.843\n",
      "INFO:tensorflow:loss = 581.37476, step = 701 (0.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.694\n",
      "INFO:tensorflow:loss = 554.26965, step = 801 (0.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.194\n",
      "INFO:tensorflow:loss = 617.8241, step = 901 (0.812 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into babyweight_trained/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:113: count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py:2322: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-04T11:46:23Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8329 thread 11 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8330 thread 11 bound to OS proc set 3\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-04-11:46:26\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.4358414, global_step = 1000, label/mean = 7.329146, loss = 734.01624, prediction/mean = 6.916374\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: babyweight_trained/model.ckpt-1000\n",
      "WARNING:tensorflow:From /home/jupyter/training-data-analyst/blogs/babyweight/babyweight/trainer/model.py:105: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'plurality': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'mother_age': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'gestation_weeks': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'is_male': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'plurality': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'mother_age': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'gestation_weeks': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'is_male': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: babyweight_trained/export/exporter/temp-1586000786/saved_model.pb\n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8285 thread 11 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 8260 tid 8287 thread 1 bound to OS proc set 1\n",
      "INFO:tensorflow:Loss for final step: 614.2201.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"bucket=${BUCKET}\"\n",
    "rm -rf babyweight_trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/babyweight\n",
    "python -m trainer.task \\\n",
    "   --bucket=${BUCKET} \\\n",
    "   --output_dir=babyweight_trained \\\n",
    "   --job-dir=./tmp \\\n",
    "   --pattern=\"00001-of-\" --train_steps=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once the code works in standalone mode, you can run it on Cloud ML Engine.  Note that doing it on the entire dataset will take a while. The training run took about <b> an hour </b> for me on STANDARD_1. So, for the purposes of Qwiklabs, this is done on a partial dataset on a smaller tier (BASIC_1). Monitor the progress of this job in the Cloud ML Engine section of the GCP Console. Once you see a green check mark, run the next Datalab cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model us-central1 babyweight_200404_114628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/checkpoint#1586000659338969...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/eval/events.out.tfevents.1529348264.cmle-training-master-a137ac0fff-0-9q8r4#1586000659412955...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/events.out.tfevents.1529347276.cmle-training-master-a137ac0fff-0-9q8r4#1586000659397422...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/export/exporter/1529355466/saved_model.pb#1586000659423101...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/export/exporter/1529355466/variables/variables.index#1586000659453453...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-342784.index#1586000659514037...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-376661.index#1586000659574009...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-342784.meta#1586000659540038...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/graph.pbtxt#1586000659532586...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-376661.data-00000-of-00003#1586000659577347...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-342784.data-00000-of-00003#1586000659524475...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-342784.data-00001-of-00003#1586000659545382...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-376661.meta#1586000659601823...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-342784.data-00002-of-00003#1586000659617754...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/export/exporter/1529355466/variables/variables.data-00000-of-00001#1586000659410990...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-390628.data-00000-of-00003#1586000659572125...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-390628.data-00001-of-00003#1586000659596425...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-376661.data-00001-of-00003#1586000659546044...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-390628.data-00002-of-00003#1586000659610915...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-376661.data-00002-of-00003#1586000659584494...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-390628.index#1586000659605246...\n",
      "Removing gs://qwiklabs-gcp-00-730a32804c55/babyweight/trained_model/model.ckpt-390628.meta#1586000659607067...\n",
      "/ [22/22 objects] 100% Done                                                     \n",
      "Operation completed over 22 objects.                                             \n",
      "ERROR: (gcloud.ai-platform.jobs.submit.training) INVALID_ARGUMENT: Field: runtime_version Error: The specified runtime version '1.4' with the Python version '' is not supported or is deprecated.  Please specify a different runtime version. See https://cloud.google.com/ml-engine/docs/runtime-version-list for a list of supported versions\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: The specified runtime version '1.4' with the Python version '' is\n",
      "      not supported or is deprecated.  Please specify a different runtime version.\n",
      "      See https://cloud.google.com/ml-engine/docs/runtime-version-list for a list\n",
      "      of supported versions\n",
      "    field: runtime_version\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'OUTDIR=gs://${BUCKET}/babyweight/trained_model\\nJOBNAME=babyweight_$(date -u +%y%m%d_%H%M%S)\\necho $OUTDIR $REGION $JOBNAME\\ngsutil -m rm -rf $OUTDIR\\ngcloud ai-platform jobs submit training $JOBNAME \\\\\\n   --region=$REGION \\\\\\n   --module-name=trainer.task \\\\\\n   --package-path=$(pwd)/babyweight/trainer \\\\\\n   --job-dir=$OUTDIR \\\\\\n   --staging-bucket=gs://$BUCKET \\\\\\n   --scale-tier=BASIC \\\\\\n   --runtime-version 1.4 \\\\\\n   -- \\\\\\n   --bucket=${BUCKET} \\\\\\n   --output_dir=${OUTDIR} \\\\\\n   --pattern=\"00001-of-\" \\\\\\n   --train_steps=2000\\n'' returned non-zero exit status 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-dcf12f39cf07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'OUTDIR=gs://${BUCKET}/babyweight/trained_model\\nJOBNAME=babyweight_$(date -u +%y%m%d_%H%M%S)\\necho $OUTDIR $REGION $JOBNAME\\ngsutil -m rm -rf $OUTDIR\\ngcloud ai-platform jobs submit training $JOBNAME \\\\\\n   --region=$REGION \\\\\\n   --module-name=trainer.task \\\\\\n   --package-path=$(pwd)/babyweight/trainer \\\\\\n   --job-dir=$OUTDIR \\\\\\n   --staging-bucket=gs://$BUCKET \\\\\\n   --scale-tier=BASIC \\\\\\n   --runtime-version 1.4 \\\\\\n   -- \\\\\\n   --bucket=${BUCKET} \\\\\\n   --output_dir=${OUTDIR} \\\\\\n   --pattern=\"00001-of-\" \\\\\\n   --train_steps=2000\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</usr/local/lib/python3.5/dist-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'OUTDIR=gs://${BUCKET}/babyweight/trained_model\\nJOBNAME=babyweight_$(date -u +%y%m%d_%H%M%S)\\necho $OUTDIR $REGION $JOBNAME\\ngsutil -m rm -rf $OUTDIR\\ngcloud ai-platform jobs submit training $JOBNAME \\\\\\n   --region=$REGION \\\\\\n   --module-name=trainer.task \\\\\\n   --package-path=$(pwd)/babyweight/trainer \\\\\\n   --job-dir=$OUTDIR \\\\\\n   --staging-bucket=gs://$BUCKET \\\\\\n   --scale-tier=BASIC \\\\\\n   --runtime-version 1.4 \\\\\\n   -- \\\\\\n   --bucket=${BUCKET} \\\\\\n   --output_dir=${OUTDIR} \\\\\\n   --pattern=\"00001-of-\" \\\\\\n   --train_steps=2000\\n'' returned non-zero exit status 1"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/babyweight/trained_model\n",
    "JOBNAME=babyweight_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=$(pwd)/babyweight/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC \\\n",
    "   --runtime-version 1.4 \\\n",
    "   -- \\\n",
    "   --bucket=${BUCKET} \\\n",
    "   --output_dir=${OUTDIR} \\\n",
    "   --pattern=\"00001-of-\" \\\n",
    "   --train_steps=2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Training finished with a RMSE of 1 lb.  Obviously, this is our first model. We could probably add in some features, discretize the mother's age, and do some hyper-parameter tuning to get to a lower RMSE.  I'll leave that to you.  If you create a better model, I'd love to hear about it -- please do write a short blog post about what you did, and tweet it at me -- @lak_gcp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor training with TensorBoard\n",
    "\n",
    "To activate TensorBoard within the JupyterLab UI navigate to \"<b>File</b>\" - \"<b>New Launcher</b>\".   Then double-click the 'Tensorboard' icon on the bottom row.\n",
    "\n",
    "TensorBoard 1 will appear in the new tab.  Navigate through the three tabs to see the active TensorBoard.   The 'Graphs' and 'Projector' tabs offer very interesting information including the ability to replay the tests.\n",
    "\n",
    "You may close the TensorBoard tab when you are finished exploring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<table width=\"70%\">\n",
    "<tr><td><img src=\"weights.png\"/></td><td><img src=\"rmse.png\" /></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Make sure that training is complete before you move to the next step. Visit the Cloud ML Engine web console and <b> wait until you see a green check mark before you proceed </b>\n",
    "<p>\n",
    "<h2> Deploy trained model </h2>\n",
    "<p>\n",
    "Deploying the trained model to act as a REST web service is a simple gcloud call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: One or more URLs matched no objects.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'gsutil ls gs://${BUCKET}/babyweight/trained_model/export/exporter\\n'' returned non-zero exit status 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-82a799eedec1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gsutil ls gs://${BUCKET}/babyweight/trained_model/export/exporter\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</usr/local/lib/python3.5/dist-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'gsutil ls gs://${BUCKET}/babyweight/trained_model/export/exporter\\n'' returned non-zero exit status 1"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/babyweight/trained_model/export/exporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you are getting error then wait for a minute and run the command again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting and deploying babyweight qwiklab from  ... this will take a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: One or more URLs matched no objects.\n",
      "Created ml engine model [projects/qwiklabs-gcp-00-730a32804c55/models/babyweight].\n",
      "ERROR: (gcloud.ai-platform.versions.create) argument --origin: expected one argument\n",
      "Usage: gcloud ai-platform versions create VERSION --model=MODEL [optional flags]\n",
      "  optional flags may be  --async | --config | --description | --framework |\n",
      "                         --help | --labels | --origin | --python-version |\n",
      "                         --runtime-version | --staging-bucket\n",
      "\n",
      "For detailed information on this command and its flags, run:\n",
      "  gcloud ai-platform versions create --help\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'MODEL_NAME=\"babyweight\"\\nMODEL_VERSION=\"qwiklab\"\\nMODEL_LOCATION=$(gsutil ls gs://${BUCKET}/babyweight/trained_model/export/exporter/ | tail -1)\\necho \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\\n#gcloud ai-platform versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\\n#gcloud ai-platform models delete ${MODEL_NAME}\\ngcloud ai-platform models create ${MODEL_NAME} --regions $REGION\\ngcloud ai-platform versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version 1.4\\n'' returned non-zero exit status 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-dc4aac182736>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MODEL_NAME=\"babyweight\"\\nMODEL_VERSION=\"qwiklab\"\\nMODEL_LOCATION=$(gsutil ls gs://${BUCKET}/babyweight/trained_model/export/exporter/ | tail -1)\\necho \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\\n#gcloud ai-platform versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\\n#gcloud ai-platform models delete ${MODEL_NAME}\\ngcloud ai-platform models create ${MODEL_NAME} --regions $REGION\\ngcloud ai-platform versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version 1.4\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</usr/local/lib/python3.5/dist-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'MODEL_NAME=\"babyweight\"\\nMODEL_VERSION=\"qwiklab\"\\nMODEL_LOCATION=$(gsutil ls gs://${BUCKET}/babyweight/trained_model/export/exporter/ | tail -1)\\necho \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\\n#gcloud ai-platform versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\\n#gcloud ai-platform models delete ${MODEL_NAME}\\ngcloud ai-platform models create ${MODEL_NAME} --regions $REGION\\ngcloud ai-platform versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version 1.4\\n'' returned non-zero exit status 2"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"babyweight\"\n",
    "MODEL_VERSION=\"qwiklab\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/babyweight/trained_model/export/exporter/ | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ai-platform versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ai-platform models delete ${MODEL_NAME}\n",
    "gcloud ai-platform models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ai-platform versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h2> Use model to predict </h2>\n",
    "<p>\n",
    "Send a JSON request to the endpoint of the service to make it predict a baby's weight ... I am going to try out how well the model would have predicted the weights of our two kids and a couple of variations while we are at it ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 404 when requesting https://ml.googleapis.com/v1/projects/qwiklabs-gcp-00-730a32804c55/models/babyweight/versions/qwiklab:predict?alt=json returned \"Field: name Error: The model resource: \"babyweight\" was not found. Please create the Cloud ML model resource first by using 'gcloud ml-engine models create babyweight'.\". Details: \"[{'@type': 'type.googleapis.com/google.rpc.BadRequest', 'fieldViolations': [{'field': 'name', 'description': 'The model resource: \"babyweight\" was not found. Please create the Cloud ML model resource first by using \\'gcloud ml-engine models create babyweight\\'.'}]}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-fd04d81defc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'projects/%s/models/%s/versions/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mPROJECT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'babyweight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'qwiklab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"response={0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 404 when requesting https://ml.googleapis.com/v1/projects/qwiklabs-gcp-00-730a32804c55/models/babyweight/versions/qwiklab:predict?alt=json returned \"Field: name Error: The model resource: \"babyweight\" was not found. Please create the Cloud ML model resource first by using 'gcloud ml-engine models create babyweight'.\". Details: \"[{'@type': 'type.googleapis.com/google.rpc.BadRequest', 'fieldViolations': [{'field': 'name', 'description': 'The model resource: \"babyweight\" was not found. Please create the Cloud ML model resource first by using \\'gcloud ml-engine models create babyweight\\'.'}]}]\">"
     ]
    }
   ],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build('ml', 'v1', credentials=credentials)\n",
    "\n",
    "request_data = {'instances':\n",
    "  [\n",
    "    {\n",
    "      'is_male': 'True',\n",
    "      'mother_age': 26.0,\n",
    "      'plurality': 'Single(1)',\n",
    "      'gestation_weeks': 39\n",
    "    },\n",
    "    {\n",
    "      'is_male': 'False',\n",
    "      'mother_age': 29.0,\n",
    "      'plurality': 'Single(1)',\n",
    "      'gestation_weeks': 38\n",
    "    },\n",
    "    {\n",
    "      'is_male': 'True',\n",
    "      'mother_age': 26.0,\n",
    "      'plurality': 'Triplets(3)',\n",
    "      'gestation_weeks': 39\n",
    "    },\n",
    "    {\n",
    "      'is_male': 'Unknown',\n",
    "      'mother_age': 29.0,\n",
    "      'plurality': 'Multiple(2+)',\n",
    "      'gestation_weeks': 38\n",
    "    },\n",
    "  ]\n",
    "}\n",
    "\n",
    "parent = 'projects/%s/models/%s/versions/%s' % (PROJECT, 'babyweight', 'qwiklab')\n",
    "response = api.projects().predict(body=request_data, name=parent).execute()\n",
    "print (\"response={0}\".format(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Copyright 2018 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
